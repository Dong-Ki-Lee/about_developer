# 학습 모델의 종류 (지도 학습)

learning 의 분류는 다음과 같다.

* 결과 label이 존재하는지 아닌지 (지도, 비지도, 준지도, 강화학습)
* 실시간으로 학습을 하는지 (온라인, 배치)
* 기존에 알고있는 데이터 포인트와 새로운 데이터 포인트를 비교하는 것 (사례 기반 학습)
  훈련 데이터셋에서 패턴을 발견하여 예측 모델을 만드는 것 (모델 기반 학습)



## 지도 학습 (Supervised Learning)

#### 정의

훈련 데이터에 label 이라고 하는 원하는 답이 포함되는 학습

#### 예시

금연을 할지 안할지 예측하는 문제가 있다고 하고, 그 데이터가 성별, 금연교육 참여여부, 나이 등으로 이루어져있다고 치자. 각각에 데이터에 해당하는 사람이 금연을 했는지, 금연을 안했는지에 대한 데이터를 포함하고 학습시켜, 새로운 데이터에 대해서 그 사람이 금연을 할 것인지 예측한다고 하면 금연 여부라는 label을 포함하여 학습을 하는 지도학습을 한 것이다.

#### 종류

* K-Nearest Neighbers
* Linear Regression
* Logistic Regression
* Support Vector Machine
* Decision Tree, Random forest
* Neural networks

각 종류에 대해 간단하게 알아보자.



### K-Nearest Neighbers

#### 정의

범주를 알지 못하는 특정 레코드 혹은 예제의 범주를 예측하는데에 쓰인다.

#### 사용

* 얼굴 인식
* 개인 영화 추천
* 단백질 및 질병 추출

#### 방식

K라는 변수를 자연수로 정해주고, 해당 테스트 데이터에서 거리가 가장 가까운 데이터를 K개 까지 확인하고 이 K개의 라벨을 다수결을 통해 하나를 뽑아 해당 테스트 데이터의 라벨을 정한다. 



### Linear Regression

#### 정의

**예측에 필요한 정보와 예측정보가 연속형 변수일 때 사용**하는 예측방법이다.

기존 데이터를 기반으로 생성된 회귀모델을 이용해 새로운 데이터가 들어왔을 때 어떤 '값'이 될지 예측하는 문제에 적용

#### 사용

* 데이터의 변화 추세 분석
* 역학 조사
* 경제학에서 경험데이터를 사용한 미래 예측

#### 방식

가장 이해하기 쉽게 단순 선형 회귀분석을 기준으로 한다.

선형 회귀분석은 **주어진 데이터를 대표하는 하나의 직선**을 찾는 것이다.

**이 직선을 회귀선**이라고 부르고, 단순 선형 회귀분석의 경우 회귀선은 다음의 식으로 나타난다.

> y = a * x + b

선형 회귀분석에서는 이 직선의 a, b를 구하는 것이 목표이다.

여기서 대표하는 하나의 직선을 찾기위해 사용하는 방법은 최소제곱법이다.

최소제곱법은 **관측값, 예측값의 차이의 제곱을 모두 더한 값을 최소**로 만드는 것이다.

< 수식 필요 >

a, b 를 바꿔가며 위 값을 최소로 만드는 a, b 값으로 수렴해 가는 과정을 진행한다.



### Logistic Regression

#### 정의

기존 특성을 기반으로 특정 상태일 가능성을 예측

새로운 데이터가 들어왔을 때 기존 데이터의 어떤 그룹에 속하는지 분류하는 문제에 사용

다만 로지스틱 회귀분석은 범주가 2가지 범주로 나눠진 경우에만 적용된다.

다항 로지스틱 회귀분석도 있지만, 일반적으로는 이항 로지스틱 회기분석을 말한다.

#### 사용

* 의학(부상을 입은 환자들의 사망예측-TRISS)
* 소셜분석

#### 방식

선형 회귀분석의 방식으로 회귀선을 찾아내고, 그 결과값을 확률로 하여 0.5이상은 A, 0.5이하는 B라고 분류하자는 방식이다.

이때, 회귀선의 결과값 y를 그대로 사용하면 확률값이랑 맞지 않기 때문에, 확률값 0~1 사이의 값을 가지게 수식을 사용해서 값을 조정해준다.



### Support Vector Machine

#### 정의

데이터의 공간의 **범주를 가장 잘 나눌 수** 있는 **Hyperplane** 을 구하는 방법

범주는 positive samples, negative samples로 나눈다.

> Hyperplane : 데이터가 존재하는 n차원을 두 공간으로 나눌 수 있는 n-1차원의 subspace.

여기서 범주를 가장 잘 나눌 수 있다 라는 '가장 잘 나눈다' 라는 기준은 최대한 가까운 positive sample과 negative sample이 동일한 거리로 떨어져 있는 hyperplane을 찾는 것이다.

#### 사용

- 텍스트와 하이퍼텍스트를 분류
- 이미지를 분류
- 의학분야
- 손글씨의 특징 인지

#### 방식



### Decision Tree, Random Forest

#### Decision Tree 정의

사람이 이해하기 쉽게 설명을 하자면, **여러번 질문을 던지면서 대상을 좁혀나가는 '스무고개' 같은 개념**이라고 볼 수 있다.

root 노드에서 부터, 각 노드는 **데이터 공간을 가장 잘 나눌 수 있는 특징을 선택**하여 **데이터 공간을 나누**게 된다. 예를들어 기상청 날씨 데이터라고 한다면, 노드에서 나누는 특징이 '비가 왔는가?' 라는 특징으로 나눈다면, 여기서는 비가 온 날의 데이터, 비가 오지 않은 날의 데이터 두 데이터 범주로 나뉘게 되는것이다.

이를 반복하여 데이터 공간들을 나누게 된다면, 새로운 데이터가 들어왔을 때 어떤 범주/값에 속하는 데이터인지를 파악할 수 있을것이다.

**범주를 찾거나(classification) 연속형 수치 예측(regression) 모두 가능**하다.

#### Forest 정의

Random Forests를 보기 전에, Forest 형태를 가지는 모델이 몇가지 있기 때문에, 먼저 **Forest에 대해 간단하게 설명**하고 넘어가고자 한다.

아주 간단하게, 위에 **Tree 가 모여서 된 것이 Forest** 이다.

하나의 Tree로 완벽하게 나누고자 하면, 여러가지 문제가 발생한다.

**하나의 모델의 정확도를 높게 높이는 것의 한계가 존재(또는 굉장히 어려워지고)하고**, Tree 를 대상으로 말해 정확도를 높이기 위해 세부적으로 너무 나눠버리면 학습데이터에만 적용되는 **과적합된 결과가 만들어질수도 있다.**

이런 경우때문에 나온 개념이 **부스팅 개념**이다.

부스팅 개념은 **정확도가 상대적으로 낮은 분류기를 여러개 사용함으로써 정확도를 높이는 방법**이다. 

부스팅 개념을 이용해서, Tree을 구성하되, **'여러 기준으로 선택'**된 제한된 특징 셋으로 작은 Tree, 즉 **정확도가 낮은 Tree를 여러개 만든다.**

데이터를 이 여러개의 Tree에 대입하고, **Tree 각각의 결과에 대해 다수결을 통해서 결과를 정하는 모델이 Forest 형태**를 가지는 모델이다.

위에 적어놓은 **'여러 기준으로 선택' 하는 방법에 따라서 Forest 모델이 나뉘게 된다.**

#### Random Forest 정의

Random Forest는 이름에서 알 수 있듯 제한된 특징 셋을 만드는 기준이 **'무작위로 특징을 뽑는 것'**이다. 예를들어 30개의 특성이 있다면, 6개만 랜덤하게 뽑아 6개에 대한 Tree를 만든다. 30개에서 6개를 뽑는 경우의수는 굉장히 많으므로, 수많은 Tree가 생성될 수 있다.

가령 101개의 Tree를 만들었다고 생각하면, 각 Tree에 넣어서 나온 결과가 A 인 Tree 가 80개, B인 Tree가 21개라면, 결과는 A가 되는 형식이다.

#### 사용

* 키넥트에서의 신체 트랙킹
* 일반적인 분류 문제에서, Forest 형식이 많이 쓰임

#### 방식

위 정의에서 다룸



### Neural networks

#### 정의

인간의 뉴런 구조를 참고하여, 원인들이 결과에 미치는 정도가 어느정도인지 학습하고, 새로운 데이터에 대해 결과를 예측하는 모델

#### 사용

데이터와 예측하는 데이터에 따라서 여러가지 형태로 변환되어 사용된다.

